{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmMcBIWSQeex",
    "outputId": "974e6f50-5464-428a-b14a-c4cfaf31383c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiYKF1goTx8p",
    "outputId": "b020990a-eca5-4ef1-8e15-2a4aa6cc7027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mutagen in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (1.45.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\fiansyah\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\fiansyah\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: noisereduce in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: librosa in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from noisereduce) (0.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from noisereduce) (4.62.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from noisereduce) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from noisereduce) (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from noisereduce) (3.5.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (1.1.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (0.2.2)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (1.6.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (1.0.1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (5.1.0)\n",
      "Requirement already satisfied: numba>=0.45.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (0.54.1)\n",
      "Requirement already satisfied: audioread>=2.1.5 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (2.1.9)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (0.10.3.post1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (8.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tqdm->noisereduce) (0.4.4)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from numba>=0.45.1->librosa->noisereduce) (0.37.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from numba>=0.45.1->librosa->noisereduce) (62.1.0)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa->noisereduce) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa->noisereduce) (2.26.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->librosa->noisereduce) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from soundfile>=0.10.2->librosa->noisereduce) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->noisereduce) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\fiansyah\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.46.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (62.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\fiansyah\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install mutagen\n",
    "%pip install pydub\n",
    "%pip install noisereduce\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mpyW6svkebBx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fiansyah\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import mutagen\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from mutagen.wave import WAVE\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4jHhME6lAn9",
    "outputId": "8bba86dc-501d-41bd-b3ee-dea92d0e1d5c"
   },
   "outputs": [],
   "source": [
    "induk = \"E:\\\\Capstone_Project\\\\runningan\"\n",
    "os.chdir(f'{induk}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MpZY-7oQmFPc"
   },
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "induk = \"E:\\\\Capstone_Project\\\\runningan\"\n",
    "import subprocess\n",
    "import os\n",
    "from os import walk\n",
    "import csv\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLL-eQFDZbbs"
   },
   "outputs": [],
   "source": [
    "source_path = f'{induk}\\\\speech_spectogram'\n",
    "\n",
    "source_path_depression = os.path.join(source_path, 'Depression')\n",
    "source_path_normal = os.path.join(source_path, 'Normal')\n",
    "\n",
    "source_folder_depression = f\"E:\\\\Capstone_Project\\\\Depressionvsnormal_spectogram\\\\Depression\"\n",
    "destination_folder_depression = source_path_depression\n",
    "source_folder_normal = f\"E:\\\\Capstone_Project\\\\Depressionvsnormal_spectogram\\\\Normal\"\n",
    "destination_folder_normal = source_path_normal\n",
    "\n",
    "# fetch all files\n",
    "\n",
    "shutil.copytree(source_folder_depression, destination_folder_depression)\n",
    "shutil.copytree(source_folder_normal, destination_folder_normal)\n",
    "\n",
    "\n",
    "# os.listdir returns a list containing all files under the given path\n",
    "print(f\"There are {len(os.listdir( destination_folder_depression))} images of Depression.\")\n",
    "print(f\"There are {len(os.listdir(destination_folder_normal))} images of Normal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ay2gtIFyZs18"
   },
   "outputs": [],
   "source": [
    "# Define root directory\n",
    "root_dir = f'{induk}\\\\depressionvsnormal\\\\'\n",
    "\n",
    "# Empty directory to prevent FileExistsError is the function is run several times\n",
    "if os.path.exists(root_dir):\n",
    "  shutil.rmtree(root_dir)\n",
    "\n",
    "# GRADED FUNCTION: create_train_test_dirs\n",
    "def create_train_test_dirs(root_path):\n",
    "  ### START CODE HERE\n",
    "\n",
    "  # HINT:\n",
    "  # Use os.makedirs to create your directories with intermediate subdirectories\n",
    "  # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n",
    "  os.makedirs(os.path.join(root_path, \"training/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"testing/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"training/Depression/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"testing/Depression/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"training/Normal/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"testing/Normal/\"))\n",
    "  pass\n",
    "  \n",
    "  ### END CODE HERE\n",
    "\n",
    "  \n",
    "try:\n",
    "  create_train_test_dirs(root_path=root_dir)\n",
    "except FileExistsError:\n",
    "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gi0tnZpEaI2V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Capstone_Project\\runningan\\depressionvsnormal\\testing\n",
      "E:\\Capstone_Project\\runningan\\depressionvsnormal\\training\n",
      "E:\\Capstone_Project\\runningan\\depressionvsnormal\\testing\\Depression\n",
      "E:\\Capstone_Project\\runningan\\depressionvsnormal\\testing\\Normal\n",
      "E:\\Capstone_Project\\runningan\\depressionvsnormal\\training\\Depression\n",
      "E:\\Capstone_Project\\runningan\\depressionvsnormal\\training\\Normal\n"
     ]
    }
   ],
   "source": [
    "# Test your create_train_test_dirs function\n",
    "\n",
    "for rootdir, dirs, files in os.walk(root_dir):\n",
    "    for subdir in dirs:\n",
    "        print(os.path.join(rootdir, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OgarIlFdaTM2"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: split_data\n",
    "from shutil import copyfile\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "\n",
    "  ### START CODE HERE\n",
    "  file_dipakai = []\n",
    "  for file in os.listdir(SOURCE):\n",
    "    full_file_address= SOURCE + file\n",
    "    if os.path.getsize(full_file_address)>0:\n",
    "      file_dipakai.append(file)\n",
    "    else:\n",
    "      print(f\"{file} is zero length, so ignoring.\")\n",
    "  \n",
    "  jumlah_training = int(int(len(file_dipakai))*SPLIT_SIZE)\n",
    "  jumlah_testing = int(int(len(file_dipakai)-jumlah_training))\n",
    "  file_dipakai_sudah_random = random.sample(file_dipakai, len(file_dipakai))\n",
    "  files_training = file_dipakai_sudah_random[0:jumlah_training]\n",
    "  files_testing = file_dipakai_sudah_random[-jumlah_testing:]\n",
    "\n",
    "  for file_training in files_training:\n",
    "    try:\n",
    "      file = SOURCE + file_training\n",
    "      tempat_copy= TRAINING + file_training\n",
    "      copyfile(file, tempat_copy)\n",
    "    except:\n",
    "      pass\n",
    "  for file_testing in files_testing:\n",
    "    try:\n",
    "      file = SOURCE + file_testing\n",
    "      tempat_copy= TESTING + file_testing\n",
    "      copyfile(file, tempat_copy)\n",
    "    except:\n",
    "      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nNF7U1KEadXk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3292 images of depression for training\n",
      "There are 366 images of depression for testing\n",
      "There are 4706 images of normal for training\n",
      "There are 523 images of normal for testing\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Test your split_data function\n",
    "TRAINING_DIR = \"E:\\\\Capstone_Project\\\\runningan\\\\depressionvsnormal\\\\training\\\\\"\n",
    "TESTING_DIR = \"E:\\\\Capstone_Project\\\\runningan\\\\depressionvsnormal\\\\testing\\\\\"\n",
    "\n",
    "# Define paths\n",
    "DEPRESSION_SOURCE_DIR = \"E:\\\\Capstone_Project\\\\runningan\\\\speech_spectogram\\\\Depression\\\\\"\n",
    "TRAINING_DEPRESSIONS_DIR = os.path.join(TRAINING_DIR, \"Depression\\\\\")\n",
    "TESTING_DEPRESSIONS_DIR = os.path.join(TESTING_DIR, \"Depression\\\\\")\n",
    "\n",
    "NORMAL_SOURCE_DIR = \"E:\\\\Capstone_Project\\\\runningan\\\\speech_spectogram\\\\Normal\\\\\"\n",
    "TRAINING_NORMAL_DIR = os.path.join(TRAINING_DIR, \"Normal\\\\\")\n",
    "TESTING_NORMAL_DIR = os.path.join(TESTING_DIR, \"Normal\\\\\")\n",
    "\n",
    "# Empty directories in case you run this cell multiple times\n",
    "if len(os.listdir(TRAINING_DEPRESSIONS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_DEPRESSIONS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TESTING_DEPRESSIONS_DIR)) > 0:\n",
    "  for file in os.scandir(TESTING_DEPRESSIONS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TRAINING_NORMAL_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_NORMAL_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TESTING_NORMAL_DIR)) > 0:\n",
    "  for file in os.scandir(TESTING_NORMAL_DIR):\n",
    "    os.remove(file.path)\n",
    "\n",
    "# Define proportion of images used for training\n",
    "split_size = .9\n",
    "\n",
    "# Run the function\n",
    "# NOTE: Messages about zero length images should be printed out\n",
    "split_data(DEPRESSION_SOURCE_DIR, TRAINING_DEPRESSIONS_DIR, TESTING_DEPRESSIONS_DIR, split_size)\n",
    "split_data(NORMAL_SOURCE_DIR, TRAINING_NORMAL_DIR, TESTING_NORMAL_DIR, split_size)\n",
    "\n",
    "# Check that the number of images matches the expected output\n",
    "print(f\"There are {len(os.listdir(TRAINING_DEPRESSIONS_DIR))} images of depression for training\")\n",
    "print(f\"There are {len(os.listdir(TESTING_DEPRESSIONS_DIR))} images of depression for testing\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_NORMAL_DIR))} images of normal for training\")\n",
    "print(f\"There are {len(os.listdir(TESTING_NORMAL_DIR))} images of normal for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aPs-LLHLasJ_"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_val_generators\n",
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "  ### START CODE HERE\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "\n",
    "  # Pass in the appropiate arguments to the flow_from_directory method\n",
    "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=10,\n",
    "                                                      class_mode='binary',\n",
    "                                                      color_mode = 'rgb',\n",
    "                                                      shuffle=True,\n",
    "                                                      seed=42,\n",
    "                                                      target_size=(512, 512))\n",
    "\n",
    "                                                           \n",
    "     \n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "\n",
    "  # Pass in the appropiate arguments to the flow_from_directory method\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                      batch_size=10,\n",
    "                                                      class_mode='binary',\n",
    "                                                      color_mode = 'rgb',\n",
    "                                                      shuffle=True,\n",
    "                                                      seed=42,\n",
    "                                                      target_size=(512, 512))\n",
    "  \n",
    "  ### END CODE HERE\n",
    "  return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jCHwI5E-eTwZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7998 images belonging to 2 classes.\n",
      "Found 889 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test your generators\n",
    "train_generator, validation_generator = train_val_generators(TRAINING_DIR, TESTING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PB0Ar7lprxVD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\fiansyah\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "Fplq9dY0efjX"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_model\n",
    "\n",
    "def create_model():\n",
    "  # USE AT LEAST 3 CONVOLUTION LAYERS\n",
    "\n",
    "  ### START CODE HERE\n",
    "\n",
    "  model = tf.keras.models.Sequential([ \n",
    "# YOUR CODE HERE\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(512,512,3)),\n",
    "  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_labels, activation='sigmoid')\n",
    "  ])\n",
    "\n",
    "  opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "  model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "    \n",
    "  ### END CODE HERE\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NH1suHCZtlTg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_3 (Rescaling)     (None, 512, 512, 3)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 512, 512, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 256, 256, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 256, 256, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 128, 128, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 128, 128, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 64, 64, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 262144)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               33554560  \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,578,402\n",
      "Trainable params: 33,578,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Epoch 1/10\n",
      " 48/800 [>.............................] - ETA: 25:39 - loss: 0.6871 - accuracy: 0.5938"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()\n",
    "print()\n",
    "\n",
    "# Train the model\n",
    "# Note that this may take some time.\n",
    "EPOCHS = 10\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGtMAUxyer1s"
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.show()\n",
    "print(\"\")\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import os\n",
    "from tensorflow.keras import models\n",
    "from flask import Flask, request\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "data_dir = pathlib.Path(TESTING_DIR)\n",
    "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "num_labels = len(commands)\n",
    "print('Commands:', commands)\n",
    "\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "num_samples = len(filenames)\n",
    "print('Number of total examples:', num_samples)\n",
    "print('Number of examples per label:',\n",
    "      len(tf.io.gfile.listdir(str(data_dir / commands[0]))))\n",
    "print('Example file tensor:', filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram_and_label_id(audio_file, label):\n",
    "    spectrogram = audio_file\n",
    "    spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "    label_id = tf.argmax(label == commands)\n",
    "    return spectrogram, label_id\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2]\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform = file_path\n",
    "    return waveform, label\n",
    "\n",
    "def preprocess_dataset(files):\n",
    "    files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "    output_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "    output_ds = output_ds.map(\n",
    "        get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
    "    return output_ds\n",
    "\n",
    "def transformator(file):\n",
    "    IMG_PATH = file\n",
    "    image = cv2.imread(IMG_PATH)\n",
    "    image = cv2.resize(image, (512, 512))\n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "test_files = filenames\n",
    "test_ds = preprocess_dataset(test_files)\n",
    "\n",
    "test_audio = []\n",
    "test_labels = []\n",
    "for audio, label in test_ds.as_numpy_iterator():\n",
    "    test_audio.append(str(audio[0].decode(\"utf-8\")))\n",
    "    test_labels.append(label)\n",
    "\n",
    "#Normal [1] , Depresi [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benar = 0\n",
    "salah = 0\n",
    "for i in range(10):\n",
    "    y_pred = np.argmax(model.predict(transformator(test_audio[i])), axis=1)\n",
    "    y_true = test_labels[i]\n",
    "    if str(y_pred[0]) == str(y_true):\n",
    "       benar+=1\n",
    "    else:\n",
    "       salah+=1\n",
    "keakuratan = benar/(benar+salah) *100\n",
    "print(\"keakuratan {} %\".format(keakuratan))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(test_audio), axis=1)\n",
    "y_true = test_labels\n",
    "\n",
    "test_acc = sum(y_pred == y_true) / len(y_true)\n",
    "print(f'Test set accuracy: {test_acc:.0%}')\n",
    "\n",
    "confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_mtx, xticklabels=commands, yticklabels=commands,\n",
    "            annot=True, fmt='g')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Label')\n",
    "plt.show()\n",
    "\n",
    "test_dir = pathlib.Path(\"E:\\Capstone_Project\\Depressionvsnormal_spectogram\\Depression\")\n",
    "sample_file = test_dir / 'Depression0.jpg'\n",
    "\n",
    "sample_ds = preprocess_dataset([str(sample_file)])\n",
    "print(sample_ds)\n",
    "for spectrogram, label in sample_ds.batch(1):\n",
    "    prediction = model(spectrogram)\n",
    "    plt.bar(commands, tf.nn.sigmoid(prediction[0]))\n",
    "    plt.title(f'Predictions for \"{commands[label[0]]}\"')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Save the trained model as a Keras HDF5 file. \n",
    "\n",
    "saved_model_path = \"E:\\\\Capstone_Project\\\\modelh5\\\\predictive_model.h5\"\n",
    "model.save(saved_model_path)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Terbaik_2.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "42f60ef5713f6389c68d58b5cf9aed372996a4129bb1a516412447272d8a7fe7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
