{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmMcBIWSQeex",
    "outputId": "974e6f50-5464-428a-b14a-c4cfaf31383c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uiYKF1goTx8p",
    "outputId": "b020990a-eca5-4ef1-8e15-2a4aa6cc7027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mutagen in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (1.45.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\fiansyah\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\fiansyah\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: noisereduce in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: librosa in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from noisereduce) (0.9.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from noisereduce) (4.62.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from noisereduce) (1.20.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from noisereduce) (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from noisereduce) (3.5.0)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (1.1.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (0.2.2)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (1.6.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (1.0.1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (5.1.0)\n",
      "Requirement already satisfied: numba>=0.45.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (0.54.1)\n",
      "Requirement already satisfied: audioread>=2.1.5 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (2.1.9)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (0.10.3.post1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from librosa->noisereduce) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (8.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from matplotlib->noisereduce) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tqdm->noisereduce) (0.4.4)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from numba>=0.45.1->librosa->noisereduce) (0.37.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from numba>=0.45.1->librosa->noisereduce) (62.1.0)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa->noisereduce) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa->noisereduce) (2.26.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from scikit-learn>=0.19.1->librosa->noisereduce) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from soundfile>=0.10.2->librosa->noisereduce) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->noisereduce) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa->noisereduce) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\fiansyah\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.46.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (62.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\fiansyah\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install mutagen\n",
    "%pip install pydub\n",
    "%pip install noisereduce\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mpyW6svkebBx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fiansyah\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import mutagen\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from mutagen.wave import WAVE\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g4jHhME6lAn9",
    "outputId": "8bba86dc-501d-41bd-b3ee-dea92d0e1d5c"
   },
   "outputs": [],
   "source": [
    "induk = \"E:\\\\Capstone_Project\\\\runningan\"\n",
    "os.chdir(f'{induk}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MpZY-7oQmFPc"
   },
   "outputs": [],
   "source": [
    "# Importing relevant libraries\n",
    "induk = \"E:\\\\Capstone_Project\\\\runningan\"\n",
    "import subprocess\n",
    "import os\n",
    "from os import walk\n",
    "import csv\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLL-eQFDZbbs"
   },
   "outputs": [],
   "source": [
    "source_path = f'{induk}\\\\speech_spectogram'\n",
    "\n",
    "source_path_depression = os.path.join(source_path, 'Depression')\n",
    "source_path_normal = os.path.join(source_path, 'Normal')\n",
    "\n",
    "source_folder_depression = f\"E:\\\\Capstone_Project\\\\Depressionvsnormal_spectogram\\\\Depression\"\n",
    "destination_folder_depression = source_path_depression\n",
    "source_folder_normal = f\"E:\\\\Capstone_Project\\\\Depressionvsnormal_spectogram\\\\Normal\"\n",
    "destination_folder_normal = source_path_normal\n",
    "\n",
    "# fetch all files\n",
    "\n",
    "shutil.copytree(source_folder_depression, destination_folder_depression)\n",
    "shutil.copytree(source_folder_normal, destination_folder_normal)\n",
    "\n",
    "\n",
    "# os.listdir returns a list containing all files under the given path\n",
    "print(f\"There are {len(os.listdir( destination_folder_depression))} images of Depression.\")\n",
    "print(f\"There are {len(os.listdir(destination_folder_normal))} images of Normal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ay2gtIFyZs18"
   },
   "outputs": [],
   "source": [
    "# Define root directory\n",
    "root_dir = f'{induk}\\\\depressionvsnormal\\\\'\n",
    "\n",
    "# Empty directory to prevent FileExistsError is the function is run several times\n",
    "if os.path.exists(root_dir):\n",
    "  shutil.rmtree(root_dir)\n",
    "\n",
    "# GRADED FUNCTION: create_train_test_dirs\n",
    "def create_train_test_dirs(root_path):\n",
    "  ### START CODE HERE\n",
    "\n",
    "  # HINT:\n",
    "  # Use os.makedirs to create your directories with intermediate subdirectories\n",
    "  # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n",
    "  os.makedirs(os.path.join(root_path, \"training/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"testing/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"training/Depression/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"testing/Depression/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"training/Normal/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"testing/Normal/\"))\n",
    "  pass\n",
    "  \n",
    "  ### END CODE HERE\n",
    "\n",
    "  \n",
    "try:\n",
    "  create_train_test_dirs(root_path=root_dir)\n",
    "except FileExistsError:\n",
    "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gi0tnZpEaI2V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Capstone_Project\\runningan\\depressionvsnormal\\testing\n",
      "E:\\Capstone_Project\\runningan\\depressionvsnormal\\training\n",
      "E:\\Capstone_Project\\runningan\\depressionvsnormal\\testing\\Depression\n",
      "E:\\Capstone_Project\\runningan\\depressionvsnormal\\testing\\Normal\n",
      "E:\\Capstone_Project\\runningan\\depressionvsnormal\\training\\Depression\n",
      "E:\\Capstone_Project\\runningan\\depressionvsnormal\\training\\Normal\n"
     ]
    }
   ],
   "source": [
    "# Test your create_train_test_dirs function\n",
    "\n",
    "for rootdir, dirs, files in os.walk(root_dir):\n",
    "    for subdir in dirs:\n",
    "        print(os.path.join(rootdir, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "OgarIlFdaTM2"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: split_data\n",
    "from shutil import copyfile\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "\n",
    "  ### START CODE HERE\n",
    "  file_dipakai = []\n",
    "  for file in os.listdir(SOURCE):\n",
    "    full_file_address= SOURCE + file\n",
    "    if os.path.getsize(full_file_address)>0:\n",
    "      file_dipakai.append(file)\n",
    "    else:\n",
    "      print(f\"{file} is zero length, so ignoring.\")\n",
    "  \n",
    "  jumlah_training = int(int(len(file_dipakai))*SPLIT_SIZE)\n",
    "  jumlah_testing = int(int(len(file_dipakai)-jumlah_training))\n",
    "  file_dipakai_sudah_random = random.sample(file_dipakai, len(file_dipakai))\n",
    "  files_training = file_dipakai_sudah_random[0:jumlah_training]\n",
    "  files_testing = file_dipakai_sudah_random[-jumlah_testing:]\n",
    "\n",
    "  for file_training in files_training:\n",
    "    try:\n",
    "      file = SOURCE + file_training\n",
    "      tempat_copy= TRAINING + file_training\n",
    "      copyfile(file, tempat_copy)\n",
    "    except:\n",
    "      pass\n",
    "  for file_testing in files_testing:\n",
    "    try:\n",
    "      file = SOURCE + file_testing\n",
    "      tempat_copy= TESTING + file_testing\n",
    "      copyfile(file, tempat_copy)\n",
    "    except:\n",
    "      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nNF7U1KEadXk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3292 images of depression for training\n",
      "There are 366 images of depression for testing\n",
      "There are 4706 images of normal for training\n",
      "There are 523 images of normal for testing\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Test your split_data function\n",
    "TRAINING_DIR = \"E:\\\\Capstone_Project\\\\runningan\\\\depressionvsnormal\\\\training\\\\\"\n",
    "TESTING_DIR = \"E:\\\\Capstone_Project\\\\runningan\\\\depressionvsnormal\\\\testing\\\\\"\n",
    "\n",
    "# Define paths\n",
    "DEPRESSION_SOURCE_DIR = \"E:\\\\Capstone_Project\\\\runningan\\\\speech_spectogram\\\\Depression\\\\\"\n",
    "TRAINING_DEPRESSIONS_DIR = os.path.join(TRAINING_DIR, \"Depression\\\\\")\n",
    "TESTING_DEPRESSIONS_DIR = os.path.join(TESTING_DIR, \"Depression\\\\\")\n",
    "\n",
    "NORMAL_SOURCE_DIR = \"E:\\\\Capstone_Project\\\\runningan\\\\speech_spectogram\\\\Normal\\\\\"\n",
    "TRAINING_NORMAL_DIR = os.path.join(TRAINING_DIR, \"Normal\\\\\")\n",
    "TESTING_NORMAL_DIR = os.path.join(TESTING_DIR, \"Normal\\\\\")\n",
    "\n",
    "# Empty directories in case you run this cell multiple times\n",
    "if len(os.listdir(TRAINING_DEPRESSIONS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_DEPRESSIONS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TESTING_DEPRESSIONS_DIR)) > 0:\n",
    "  for file in os.scandir(TESTING_DEPRESSIONS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TRAINING_NORMAL_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_NORMAL_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TESTING_NORMAL_DIR)) > 0:\n",
    "  for file in os.scandir(TESTING_NORMAL_DIR):\n",
    "    os.remove(file.path)\n",
    "\n",
    "# Define proportion of images used for training\n",
    "split_size = .9\n",
    "\n",
    "# Run the function\n",
    "# NOTE: Messages about zero length images should be printed out\n",
    "split_data(DEPRESSION_SOURCE_DIR, TRAINING_DEPRESSIONS_DIR, TESTING_DEPRESSIONS_DIR, split_size)\n",
    "split_data(NORMAL_SOURCE_DIR, TRAINING_NORMAL_DIR, TESTING_NORMAL_DIR, split_size)\n",
    "\n",
    "# Check that the number of images matches the expected output\n",
    "print(f\"There are {len(os.listdir(TRAINING_DEPRESSIONS_DIR))} images of depression for training\")\n",
    "print(f\"There are {len(os.listdir(TESTING_DEPRESSIONS_DIR))} images of depression for testing\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_NORMAL_DIR))} images of normal for training\")\n",
    "print(f\"There are {len(os.listdir(TESTING_NORMAL_DIR))} images of normal for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aPs-LLHLasJ_"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_val_generators\n",
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "  ### START CODE HERE\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "\n",
    "  # Pass in the appropiate arguments to the flow_from_directory method\n",
    "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=10,\n",
    "                                                      class_mode='binary',\n",
    "                                                      color_mode = 'rgb',\n",
    "                                                      shuffle=True,\n",
    "                                                      seed=42,\n",
    "                                                      target_size=(512, 512))\n",
    "\n",
    "                                                           \n",
    "     \n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "\n",
    "  # Pass in the appropiate arguments to the flow_from_directory method\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                      batch_size=10,\n",
    "                                                      class_mode='binary',\n",
    "                                                      color_mode = 'rgb',\n",
    "                                                      shuffle=True,\n",
    "                                                      seed=42,\n",
    "                                                      target_size=(512, 512))\n",
    "  \n",
    "  ### END CODE HERE\n",
    "  return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jCHwI5E-eTwZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7998 images belonging to 2 classes.\n",
      "Found 889 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test your generators\n",
    "train_generator, validation_generator = train_val_generators(TRAINING_DIR, TESTING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PB0Ar7lprxVD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\fiansyah\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\fiansyah\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands: ['Depression' 'Normal']\n",
      "Number of total examples: 889\n",
      "Number of examples per label: 366\n",
      "Example file tensor: tf.Tensor(b'E:\\\\Capstone_Project\\\\runningan\\\\depressionvsnormal\\\\testing\\\\Depression\\\\Depression2935.jpg', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "data_dir = pathlib.Path(TESTING_DIR)\n",
    "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "num_labels = len(commands)\n",
    "print('Commands:', commands)\n",
    "\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "num_samples = len(filenames)\n",
    "print('Number of total examples:', num_samples)\n",
    "print('Number of examples per label:',\n",
    "      len(tf.io.gfile.listdir(str(data_dir / commands[0]))))\n",
    "print('Example file tensor:', filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "Fplq9dY0efjX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional\n",
    "\n",
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([ \n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(512,512,3)),\n",
    "  tf.keras.layers.Conv2D(4, 2, strides=(1, 1),padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2),),\n",
    "  tf.keras.layers.Conv2D(8, 3, strides=(1, 1),padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2),),\n",
    "  tf.keras.layers.Conv2D(16, 4, strides=(1, 1),padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2),),\n",
    "  #Bidirectional(LSTM(2, input_shape=(64,64,16), return_sequences=True))\n",
    "  #tf.keras.layers.LSTM(2,dropout=0.5)\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_labels, activation='softmax'),\n",
    "  ])\n",
    "  \n",
    "  opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "  model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "    \n",
    "  ### END CODE HERE\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "NH1suHCZtlTg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_37 (Rescaling)    (None, 512, 512, 3)       0         \n",
      "                                                                 \n",
      " conv2d_109 (Conv2D)         (None, 512, 512, 4)       52        \n",
      "                                                                 \n",
      " max_pooling2d_108 (MaxPooli  (None, 256, 256, 4)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_110 (Conv2D)         (None, 256, 256, 8)       296       \n",
      "                                                                 \n",
      " max_pooling2d_109 (MaxPooli  (None, 128, 128, 8)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_111 (Conv2D)         (None, 128, 128, 16)      2064      \n",
      "                                                                 \n",
      " max_pooling2d_110 (MaxPooli  (None, 64, 64, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 65536)             0         \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 128)               8388736   \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,391,406\n",
      "Trainable params: 8,391,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "111/800 [===>..........................] - ETA: 8:56 - loss: 0.6831 - accuracy: 0.5793"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8216/2676682599.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Note that this may take some time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1860\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 497\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()\n",
    "print()\n",
    "\n",
    "# Train the model\n",
    "# Note that this may take some time.\n",
    "EPOCHS = 10\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "GGtMAUxyer1s"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.show()\n",
    "print(\"\")\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Save the trained model as a Keras HDF5 file. \n",
    "\n",
    "saved_model_path = \"E:\\\\Capstone_Project\\\\modelh5\\\\predictive_model.h5\"\n",
    "model.save(saved_model_path)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram_and_label_id(audio_file, label):\n",
    "    spectrogram = audio_file\n",
    "    spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "    label_id = tf.argmax(label == commands)\n",
    "    return spectrogram, label_id\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2]\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform = file_path\n",
    "    return waveform, label\n",
    "\n",
    "def preprocess_dataset(files):\n",
    "    files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "    output_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "    output_ds = output_ds.map(\n",
    "        get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
    "    return output_ds\n",
    "\n",
    "def transformator(file):\n",
    "    IMG_PATH = file\n",
    "    image = cv2.imread(IMG_PATH)\n",
    "    image = cv2.resize(image, (512, 512))\n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "test_files = filenames\n",
    "test_ds = preprocess_dataset(test_files)\n",
    "\n",
    "test_audio = []\n",
    "test_labels = []\n",
    "for audio, label in test_ds.as_numpy_iterator():\n",
    "    test_audio.append(str(audio[0].decode(\"utf-8\")))\n",
    "    test_labels.append(label)\n",
    "\n",
    "# Normal [1] , Depresi [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "keakuratan 65.0 %\n"
     ]
    }
   ],
   "source": [
    "benar = 0\n",
    "salah = 0\n",
    "for i in range(40):\n",
    "    y_pred = np.argmax(model.predict(transformator(test_audio[i])), axis=1)\n",
    "    y_true = test_labels[i]\n",
    "    if str(y_pred[0]) == str(y_true):\n",
    "       benar+=1\n",
    "    else:\n",
    "       salah+=1\n",
    "keakuratan = benar/(benar+salah) *100\n",
    "print(\"keakuratan {} %\".format(keakuratan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Terbaik_2.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "42f60ef5713f6389c68d58b5cf9aed372996a4129bb1a516412447272d8a7fe7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
