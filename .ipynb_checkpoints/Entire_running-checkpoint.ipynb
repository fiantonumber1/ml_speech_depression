{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mpyW6svkebBx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import jsons\n",
    "from flask import Flask, jsonify, request\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import mutagen\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from mutagen.wave import WAVE\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import os\n",
    "from tensorflow.keras import models\n",
    "from flask import Flask, request\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import subprocess\n",
    "from os import walk\n",
    "import csv\n",
    "import shutil\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import  spectogram_only\n",
    "import split_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Warning\n",
    "### Warning\n",
    "### Warning\n",
    "### Running for split audio and change to spectogram\n",
    "def split_and_spectogram(rootdir): #rootdir is a source of folder which contain a datasheet\n",
    "    ##### Make Split\n",
    "    induknya_1 = \"./Depressionvsnormal\"\n",
    "    folder_depresi='./Depressionvsnormal/Depression'\n",
    "    folder_normal = \"./Depressionvsnormal/Normal\"\n",
    "    try:\n",
    "        os.mkdir(induknya_1)\n",
    "    except:\n",
    "        print(\"its exist\")\n",
    "    try:\n",
    "        os.mkdir(folder_depresi)\n",
    "    except:\n",
    "        print(\"its exist\")\n",
    "    try:\n",
    "        os.mkdir(folder_normal)\n",
    "    except:\n",
    "        print(\"its exist\")\n",
    "    loopingke = split_voice.splitvoice(rootdir,folder_depresi,folder_normal)\n",
    "    \n",
    "    ##### Make Spectogram\n",
    "    induknya_2 = \"./Depressionvsnormal_spectogram\"\n",
    "    try:\n",
    "        os.mkdir(induknya_2)\n",
    "    except:\n",
    "        print(\"its exist\")\n",
    "    folder_asal_depresi = folder_depresi\n",
    "    folder_dituju_depresi = \".//Depressionvsnormal_spectogram//Depression\"\n",
    "    try:\n",
    "        os.mkdir(folder_dituju_depresi)\n",
    "    except:\n",
    "        print(\"its exist\")\n",
    "    spectogram_only.spectogram_only(folder_asal_depresi ,folder_dituju_depresi,\"Depression\")\n",
    "\n",
    "    folder_asal_normal = folder_normal\n",
    "    folder_dituju_normal = \".//Depressionvsnormal_spectogram//Normal\"\n",
    "    try:\n",
    "        os.mkdir(folder_dituju_normal)\n",
    "    except:\n",
    "        print(\"its exist\")\n",
    "    spectogram_only.spectogram_only(folder_asal_normal ,folder_dituju_normal,\"Normal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#split_and_spectogram('.\\\\Folder_Datasheet')  # Only use when need a spectogram datasheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLL-eQFDZbbs"
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "os.chdir(f'./')\n",
    "print(cwd)\n",
    "destination_folder_depression = f\"./Depressionvsnormal_spectogram//Depression\"\n",
    "destination_folder_normal = f\".//Depressionvsnormal_spectogram//Normal\"\n",
    "\n",
    "# os.listdir returns a list containing all files under the given path\n",
    "print(f\"There are {len(os.listdir( destination_folder_depression))} images of Depression.\")\n",
    "print(f\"There are {len(os.listdir(destination_folder_normal))} images of Normal.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ay2gtIFyZs18"
   },
   "outputs": [],
   "source": [
    "# Define root directory\n",
    "#make runningan folder\n",
    "induk = \".//runningan\"\n",
    "try:\n",
    "    os.mkdir(induk)\n",
    "except:\n",
    "    print(\"its exist\")\n",
    "    \n",
    "root_dir = f'{induk}\\\\depressionvsnormal\\\\'\n",
    "#make depressionvsnormal folder\n",
    "try:\n",
    "    os.mkdir(root_dir)\n",
    "except:\n",
    "    print(\"its exist\")\n",
    "\n",
    "# Empty directory to prevent FileExistsError is the function is run several times\n",
    "if os.path.exists(root_dir):\n",
    "  shutil.rmtree(root_dir)\n",
    "\n",
    "# GRADED FUNCTION: create_train_test_dirs\n",
    "def create_train_test_dirs(root_path):\n",
    "  ### START CODE HERE\n",
    "\n",
    "  # HINT:\n",
    "  # Use os.makedirs to create your directories with intermediate subdirectories\n",
    "  # Don't hardcode the paths. Use os.path.join to append the new directories to the root_path parameter\n",
    "  os.makedirs(os.path.join(root_path, \"training/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"testing/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"training/Depression/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"testing/Depression/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"training/Normal/\"))\n",
    "  os.makedirs(os.path.join(root_path, \"testing/Normal/\"))\n",
    "  pass\n",
    "  \n",
    "  ### END CODE HERE\n",
    "\n",
    "  \n",
    "try:\n",
    "  create_train_test_dirs(root_path=root_dir)\n",
    "except FileExistsError:\n",
    "  print(\"You should not be seeing this since the upper directory is removed beforehand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gi0tnZpEaI2V"
   },
   "outputs": [],
   "source": [
    "# Test your create_train_test_dirs function\n",
    "\n",
    "for rootdir, dirs, files in os.walk(root_dir):\n",
    "    for subdir in dirs:\n",
    "        print(os.path.join(rootdir, subdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OgarIlFdaTM2"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: split_data\n",
    "from shutil import copyfile\n",
    "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
    "\n",
    "  ### START CODE HERE\n",
    "  file_dipakai = []\n",
    "  for file in os.listdir(SOURCE):\n",
    "    full_file_address= SOURCE + file\n",
    "    if os.path.getsize(full_file_address)>0:\n",
    "      file_dipakai.append(file)\n",
    "    else:\n",
    "      print(f\"{file} is zero length, so ignoring.\")\n",
    "  \n",
    "  jumlah_training = int(int(len(file_dipakai))*SPLIT_SIZE)\n",
    "  jumlah_testing = int(int(len(file_dipakai)-jumlah_training))\n",
    "  file_dipakai_sudah_random = random.sample(file_dipakai, len(file_dipakai))\n",
    "  files_training = file_dipakai_sudah_random[0:jumlah_training]\n",
    "  files_testing = file_dipakai_sudah_random[-jumlah_testing:]\n",
    "\n",
    "  for file_training in files_training:\n",
    "    try:\n",
    "      file = SOURCE + file_training\n",
    "      tempat_copy= TRAINING + file_training\n",
    "      copyfile(file, tempat_copy)\n",
    "    except:\n",
    "      pass\n",
    "  for file_testing in files_testing:\n",
    "    try:\n",
    "      file = SOURCE + file_testing\n",
    "      tempat_copy= TESTING + file_testing\n",
    "      copyfile(file, tempat_copy)\n",
    "    except:\n",
    "      pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "TRAINING_DIR = \".\\\\runningan\\\\depressionvsnormal\\\\training\\\\\"\n",
    "TESTING_DIR = \".\\\\runningan\\\\depressionvsnormal\\\\testing\\\\\"\n",
    "\n",
    "# Define paths\n",
    "DEPRESSION_SOURCE_DIR = \".\\\\Depressionvsnormal_spectogram\\\\Depression\\\\\"\n",
    "TRAINING_DEPRESSIONS_DIR = os.path.join(TRAINING_DIR, \"Depression\\\\\")\n",
    "TESTING_DEPRESSIONS_DIR = os.path.join(TESTING_DIR, \"Depression\\\\\")\n",
    "\n",
    "NORMAL_SOURCE_DIR = \".\\\\Depressionvsnormal_spectogram\\\\Normal\\\\\"\n",
    "TRAINING_NORMAL_DIR = os.path.join(TRAINING_DIR, \"Normal\\\\\")\n",
    "TESTING_NORMAL_DIR = os.path.join(TESTING_DIR, \"Normal\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNF7U1KEadXk"
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "if len(os.listdir(TRAINING_DEPRESSIONS_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_DEPRESSIONS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TESTING_DEPRESSIONS_DIR)) > 0:\n",
    "  for file in os.scandir(TESTING_DEPRESSIONS_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TRAINING_NORMAL_DIR)) > 0:\n",
    "  for file in os.scandir(TRAINING_NORMAL_DIR):\n",
    "    os.remove(file.path)\n",
    "if len(os.listdir(TESTING_NORMAL_DIR)) > 0:\n",
    "  for file in os.scandir(TESTING_NORMAL_DIR):\n",
    "    os.remove(file.path)\n",
    "\n",
    "# Define proportion of images used for training\n",
    "split_size = .9\n",
    "\n",
    "# Run the function\n",
    "# NOTE: Messages about zero length images should be printed out\n",
    "split_data(DEPRESSION_SOURCE_DIR, TRAINING_DEPRESSIONS_DIR, TESTING_DEPRESSIONS_DIR, split_size)\n",
    "split_data(NORMAL_SOURCE_DIR, TRAINING_NORMAL_DIR, TESTING_NORMAL_DIR, split_size)\n",
    "\n",
    "# Check that the number of images matches the expected output\n",
    "print(f\"There are {len(os.listdir(TRAINING_DEPRESSIONS_DIR))} images of depression for training\")\n",
    "print(f\"There are {len(os.listdir(TESTING_DEPRESSIONS_DIR))} images of depression for testing\")\n",
    "print(f\"There are {len(os.listdir(TRAINING_NORMAL_DIR))} images of normal for training\")\n",
    "print(f\"There are {len(os.listdir(TESTING_NORMAL_DIR))} images of normal for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPs-LLHLasJ_"
   },
   "outputs": [],
   "source": [
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  train_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "\n",
    "  # Pass in the appropiate arguments to the flow_from_directory method\n",
    "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
    "                                                      batch_size=10,\n",
    "                                                      class_mode='binary',\n",
    "                                                      color_mode = 'rgb',\n",
    "                                                      shuffle=True,\n",
    "                                                      seed=42,\n",
    "                                                      target_size=(512, 512))\n",
    "\n",
    "                                                           \n",
    "     \n",
    "\n",
    "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
    "  validation_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
    "\n",
    "  # Pass in the appropiate arguments to the flow_from_directory method\n",
    "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
    "                                                      batch_size=10,\n",
    "                                                      class_mode='binary',\n",
    "                                                      color_mode = 'rgb',\n",
    "                                                      shuffle=True,\n",
    "                                                      seed=42,\n",
    "                                                      target_size=(512, 512))\n",
    "  \n",
    "  ### END CODE HERE\n",
    "  return train_generator, validation_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCHwI5E-eTwZ"
   },
   "outputs": [],
   "source": [
    "train_generator, validation_generator = train_val_generators(TRAINING_DIR, TESTING_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "\n",
    "data_dir = pathlib.Path(TESTING_DIR)\n",
    "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "num_labels = len(commands)\n",
    "print('Commands:', commands)\n",
    "\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "filenames = tf.random.shuffle(filenames)\n",
    "num_samples = len(filenames)\n",
    "print('Number of total examples:', num_samples)\n",
    "print('Number of examples per label:',\n",
    "      len(tf.io.gfile.listdir(str(data_dir / commands[0]))))\n",
    "print('Example file tensor:', filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fplq9dY0efjX"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([ \n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(512,512,3)),\n",
    "  tf.keras.layers.Conv2D(4, 2, strides=(1, 1),padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2),),\n",
    "  tf.keras.layers.Conv2D(8, 3, strides=(1, 1),padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2),),\n",
    "  tf.keras.layers.Conv2D(16, 4, strides=(1, 1),padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2),),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_labels, activation='sigmoid'),\n",
    "  ])\n",
    "  \n",
    "  opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "  model.compile(\n",
    "    optimizer=opt,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],)\n",
    "    \n",
    "  return model\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NH1suHCZtlTg",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "# Note that this may take some time.\n",
    "EPOCHS = 1\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGtMAUxyer1s"
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.show()\n",
    "print(\"\")\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = \"E:\\\\Capstone_Project\\\\h5_running\\\\predictive_model_v_8.h5\"\n",
    "#model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Batas penggunaan model yang sudah jadi #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectrogram_and_label_id(audio_file, label):\n",
    "    spectrogram = audio_file\n",
    "    spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "    label_id = tf.argmax(label == commands)\n",
    "    return spectrogram, label_id\n",
    "\n",
    "def get_label(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2]\n",
    "\n",
    "def get_waveform_and_label(file_path):\n",
    "    label = get_label(file_path)\n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    waveform = file_path\n",
    "    return waveform, label\n",
    "\n",
    "def preprocess_dataset(files):\n",
    "    files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "    output_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=AUTOTUNE)\n",
    "    output_ds = output_ds.map(\n",
    "        get_spectrogram_and_label_id, num_parallel_calls=AUTOTUNE)\n",
    "    return output_ds\n",
    "\n",
    "def transformator(file_gambar_spectogram):\n",
    "    IMG_PATH = file_gambar_spectogram\n",
    "    image = cv2.imread(IMG_PATH)\n",
    "    image = cv2.resize(image, (512, 512))\n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "\n",
    "def identifikasi_gambar(gambar):\n",
    "    y_pred = np.argmax(model.predict(transformator(gambar)), axis=1)\n",
    "    if str(y_pred[0]) == \"0\":\n",
    "       label_nama = \"Depresi\"\n",
    "    elif str(y_pred[0]) == \"1\":\n",
    "       label_nama = \"Normal\"\n",
    "    return label_nama\n",
    "\n",
    "def transform_audio_to_spectogram_to_testing(audio_file):\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,\n",
    "                                               fmax=8000)\n",
    "    fig, ax = plt.subplots()\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    img = librosa.display.specshow(S_dB)\n",
    "            # ax.set(title='Log Mel-frequency spectrogram')\n",
    "    folder_dituju = \"E:\\Capstone_Project\\\\runningan\\jalur_lewat_testing\"\n",
    "    savefigure = os.path.join(folder_dituju, 'jalur_lewat.jpg')\n",
    "    plt.savefig(savefigure)\n",
    "    status = identifikasi_gambar(savefigure)\n",
    "    return status\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "test_files = filenames\n",
    "test_ds = preprocess_dataset(test_files)\n",
    "\n",
    "test_audio = []\n",
    "test_labels = []\n",
    "for audio, label in test_ds.as_numpy_iterator():\n",
    "    test_audio.append(str(audio[0].decode(\"utf-8\")))\n",
    "    test_labels.append(label)\n",
    "\n",
    "# Normal [1] , Depresi [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benar = 0\n",
    "salah = 0\n",
    "for i in range(8):\n",
    "    y_pred = np.argmax(model.predict(transformator(test_audio[i])), axis=1)\n",
    "    y_true = test_labels[i]\n",
    "    if str(y_pred[0]) == str(y_true):\n",
    "       benar+=1\n",
    "    else:\n",
    "       salah+=1\n",
    "keakuratan = benar/(benar+salah) *100\n",
    "print(\"keakuratan {} %\".format(keakuratan))\n",
    "#memprediksi testing 79.125% benar untuk keseluruhan training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "Benar = 0\n",
    "Salah = 0\n",
    "\n",
    "for i in range(10):\n",
    "    try:\n",
    "        gambar = \".\\\\runningan\\\\depressionvsnormal\\\\testing\\\\Normal\\\\Normal{}.jpg\".format(i)\n",
    "        resp = identifikasi_gambar(gambar)\n",
    "        if resp == \"Depresi\":\n",
    "            Benar+=1\n",
    "        else:\n",
    "            Salah+=1\n",
    "    except:\n",
    "        print(\"\")\n",
    "        \n",
    "totalpersen = Benar / (Benar+Salah)*100\n",
    "print(Benar)\n",
    "print(Salah)\n",
    "print(totalpersen)\n",
    "#memprediksi testing 63% benar untuk cek depresi untuk  keseluruhan testin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Benar = 0\n",
    "Salah = 0\n",
    "for i in range(10):\n",
    "    try:\n",
    "        gambar = \".\\\\runningan\\\\depressionvsnormal\\\\testing\\\\Normal\\\\Normal{}.jpg\".format(i)\n",
    "        resp = identifikasi_gambar(gambar)\n",
    "        if resp == \"Normal\":\n",
    "            Benar+=1\n",
    "        else:\n",
    "            Salah+=1\n",
    "    except:\n",
    "        print(\"\")\n",
    "        \n",
    "totalpersen = Benar / (Benar+Salah)*100\n",
    "print(Benar)\n",
    "print(Salah)\n",
    "print(totalpersen)\n",
    "#memprediksi testing 89% benar untuk cek normal untuk keseluruhan testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = \".\\Depressionvsnormal\\Depression\\Depression4.wav\"\n",
    "hasil = transform_audio_to_spectogram_to_testing(audio_file)\n",
    "\n",
    "print(hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from gevent.pywsgi import WSGIServer\n",
    "\n",
    "app = Flask(__name__)\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def infer_image():\n",
    "    if request.method == 'POST':\n",
    "        if 'file' not in request.files:\n",
    "            return \"Masukan hanya jenis file saja\"\n",
    "        file = request.files.get('file')\n",
    "        try:\n",
    "            img = transform_audio_to_spectogram_to_testing(file)\n",
    "            img_respon =  { \"status_user\":img,\"status_running\":\"Sukses\"}\n",
    "        except:\n",
    "            img_respon =  { \"status_user\":\"-\",\"status_running\":\"Gagal\"}\n",
    "        return img_respon\n",
    "    \n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    return \"Selamat datang dimachine learning kami\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Debug/Development\n",
    "    # app.run(debug=True, host=\"0.0.0.0\", port=\"5000\")\n",
    "    # Production\n",
    "    http_server = WSGIServer(('127.0.0.1', 5000), app)\n",
    "    http_server.serve_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Terbaik_2.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "42f60ef5713f6389c68d58b5cf9aed372996a4129bb1a516412447272d8a7fe7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
